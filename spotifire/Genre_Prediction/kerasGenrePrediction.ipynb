{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPOTIPY_CLIENT_ID'] = '0dd677ab735f4fd1b9dbf6b236350ba1'#'32b098e058c547168c94a4fdc5dfeeba'\n",
    "os.environ['SPOTIPY_CLIENT_SECRET'] = 'bbe8736a14ba4e64bfb2d4103c8957aa'#'fb1b59216a104af69e004a30fb535612'\n",
    "os.environ['SPOTIPY_REDIRECT_URI'] = 'http://google.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spotifire'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3b2d573c6644>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspotifire\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOOSpotify\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOOSpotify\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spotifire'"
     ]
    }
   ],
   "source": [
    "from spotifire.OOSpotify.OOSpotify import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beatles = Artist('beatles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.name for i in beatles.getAlbumsAfter(1964)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_album = beatles.getAlbums()[5].getTracks()\n",
    "[[track.name,track.features] for track in white_album]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jm = Artist('john mulaney')\n",
    "jm.getAlbums()[0].AvgFeatures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corywong = Track('Cory Wong')\n",
    "corywong.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwaa = corywong.getAudioAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i['start'] for i in Track('a day in the life').getAudioAnalysis()['sections']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cwaa['segments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwaa['segments'][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Track('let it be').getAudioAnalysis()['segments'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u,username in users.items():\n",
    "    scope = 'user-library-read user-read-private'\n",
    "    token = util.prompt_for_user_token(username,scope)\n",
    "    sp = spotipy.Spotify(auth=token)\n",
    "    break\n",
    "    reqs = {'tempo':['>',140]}\n",
    "    reqs = {'valence':['>',0.55]}\n",
    "    createRadioPlaylist(['vulfpeck','chance the rapper'],username,reqs=reqs)\n",
    "    \n",
    "    break\n",
    "    artists = ['chance the rapper','alt-j']\n",
    "    createPlaylistFromTopTracks(artists,username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "# for the notebook only (not for JupyterLab) run this command once per session\n",
    "alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = data.iris()\n",
    "\n",
    "alt.Chart(iris).mark_point().encode(\n",
    "    x='petalLength',\n",
    "    y='petalWidth',\n",
    "    color='species'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "corywong = Track('cory wong')\n",
    "corywong_aa = corywong.getAudioAnalysis()\n",
    "corywong_seg = corywong_aa['segments']\n",
    "df = pd.DataFrame(corywong_seg)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,data in enumerate(zip(df.start,df.pitches,df.timbre)):\n",
    "    start,pitches,timbre = data\n",
    "    if i%25 == 0:\n",
    "        plt.figure(1)\n",
    "        plt.scatter([start]*len(pitches),pitches)\n",
    "        plt.figure(2)\n",
    "        plt.scatter([start]*len(timbre),timbre)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letitbe_seg = Track('let it be').getAudioAnalysis()['segments']\n",
    "df2 = pd.DataFrame(letitbe_seg)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,data in enumerate(zip(df2.start,df2.pitches,df2.timbre)):\n",
    "    start,pitches,timbre = data\n",
    "    if i%25 == 0:\n",
    "        plt.figure(1)\n",
    "        plt.scatter([start]*len(pitches),pitches)\n",
    "        plt.figure(2)\n",
    "        plt.scatter([start]*len(timbre),timbre)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsdc = Track('landslide dixie chicks')\n",
    "lsfm = Track('landslide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsdc_seg = lsdc.getAudioAnalysis()['segments']\n",
    "lsfm_seg = lsfm.getAudioAnalysis()['segments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(lsdc_seg)\n",
    "df3.head()\n",
    "df4 = pd.DataFrame(lsfm_seg)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,data in enumerate(zip(df.start,df.pitches,df.timbre)):\n",
    "    start,pitches,timbre = data\n",
    "    if i%25 == 0:\n",
    "        plt.figure(1)\n",
    "        plt.scatter([start]*len(pitches),pitches,c='GREEN')\n",
    "        plt.figure(2)\n",
    "        plt.scatter([start]*len(timbre),timbre,c='GREEN')\n",
    "for i,data in enumerate(zip(df3.start,df3.pitches,df3.timbre)):\n",
    "    start,pitches,timbre = data\n",
    "    if i%25 == 0:\n",
    "        plt.figure(1)\n",
    "        plt.scatter([start]*len(pitches),pitches,c='BLUE')\n",
    "        plt.figure(2)\n",
    "        plt.scatter([start]*len(timbre),timbre,c='BLUE')\n",
    "#plt.show()\n",
    "for i,data in enumerate(zip(df4.start,df4.pitches,df4.timbre)):\n",
    "    start,pitches,timbre = data\n",
    "    if i%25 == 0:\n",
    "        plt.figure(1)\n",
    "        plt.scatter([start]*len(pitches),pitches,c='RED')\n",
    "        plt.figure(2)\n",
    "        plt.scatter([start]*len(timbre),timbre,c='RED')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Artist('fleetwood mac').genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Artist('dixie chicks').genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pylast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylast\n",
    "pyAPI = '6c4f2ca3dd6bedbdc2f48a22344e2ecd'\n",
    "pySECRET = 'fd5175fa9e538986accd25dd0fc56c30'\n",
    "pl = pylast.LastFMNetwork(api_key=pyAPI,api_secret=pySECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = pl.get_track(title='cory wong',artist='vulfpeck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Playlist('sounds of funk').Attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.user_playlist_tracks('thesoundsofspotify',playlist_id='4GMYsnPRt6GT3VARNJQeKt')['items'][0]['track']['artists']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex practice\n",
    "import re\n",
    "regex = r\"(The Sound of )+.* *[a-z]$\"\n",
    "regex2 = r\"([The Sound of Rap|The Sound of Jazz])\"\n",
    "a=['The Sound of Rap','The Sound of Jazz','The Sound of London EN','tso jax']\n",
    "[i for i in a if re.search(regex,i)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "sos = User('thesoundsofspotify')\n",
    "allplaylists = sos.getPlaylists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in allplaylists:\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r\"(The Sound of )+.* *[a-z]$\"\n",
    "tso = 'the sound of '\n",
    "simple_genres = [tso+i for i in ['rock','pop','alternative rock','electronic','jazz','classical',\n",
    "                     'folk','indie rock','blues','soundtrack','bluegrass','gospel',\n",
    "                     'country','grunge','ska punk','metal','reggae','rap','punk rock','dubstep','motown','edm','emo','hip hop']]\n",
    "#genre_playlists = [i for i in sos.getPlaylists() if re.search(regex,i.name)]\n",
    "genre_playlists = [i for i in allplaylists if i.name.lower() in simple_genres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(genre_playlists))\n",
    "[i.name for i in genre_playlists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_tracks = [i.getTracks() for i in genre_playlists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{}\\n'.format([len(i) for i in genre_tracks]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_tracks[0][0].getAudioAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#genre_audio_analysis = [[x.getAudioAnalysis() for x in genre] for genre in genre_tracks]\n",
    "#list comprehension is cool, but it might be better not to use it in this case in order to get an idea \n",
    "#of the progress you're making because it'll take forevvvvver\n",
    "import pickle\n",
    "genre_audio_analysis = []\n",
    "for i,genre in enumerate(genre_tracks):\n",
    "    single_genre = []\n",
    "    for track in genre:\n",
    "        try:\n",
    "            single_genre.append(track.getAudioAnalysis())\n",
    "        except:\n",
    "            scope = 'user-library-read user-read-private'\n",
    "            token = util.prompt_for_user_token(users['zach'],scope)\n",
    "            sp = spotipy.Spotify(auth=token)\n",
    "            single_genre.append(track.getAudioAnalysis())\n",
    "    pickle.dump(single_genre,open('{}.p'.format(genre_playlists[i].name),'wb'))        \n",
    "    genre_audio_analysis.append(single_genre)\n",
    "    print('Completed {}'.format(genre_playlists[i].name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_audio_analysis = []\n",
    "for i in range(len(genre_playlists)):\n",
    "    genre_audio_analysis.append(pickle.load(open(genre_playlists[i].name+'.p','rb')))\n",
    "    print('loaded',genre_playlists[i].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(genre_audio_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre,playlist,tracks in zip(genre_audio_analysis,genre_playlists,genre_tracks):\n",
    "    print(playlist.name,len(genre),len(tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(genre_playlists,open('genre_playlists.p','wb'))\n",
    "pickle.dump(genre_tracks,open('genre_tracks.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pickle.load(open('genre_playlists.p','rb'))\n",
    "a[0].tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pickle.load(open('genre_tracks.p','rb'))\n",
    "b[0][0].Attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pl = pickle.load(open('genre_playlists.p','rb')) #playlist list\n",
    "tr = pickle.load(open('genre_tracks.p','rb')) #track list for each playlist\n",
    "aa = [pickle.load(open(p.name+'.p','rb')) for p in pl] #audio analysis for each track for each playlist\n",
    "print(len(pl),len(tr),len(aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.name for i in pl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "genreDict = {}\n",
    "for i,playlist in enumerate(pl):\n",
    "    gname = ' '.join(playlist.name.split()[3:])\n",
    "    genreDict[gname] = {}\n",
    "    genreDict[gname]['id'] = i\n",
    "    genreDict[gname]['playlistName'] = playlist.name\n",
    "    genreDict[gname]['playlistObject'] = playlist\n",
    "    genreDict[gname]['trackList'] = []\n",
    "    genreDict[gname]['trackDict'] = []\n",
    "    for track,aud in zip(tr[i],aa[i]):\n",
    "        genreDict[gname]['trackList'].append((track.name,track.artists[0]['name']))\n",
    "        genreDict[gname]['trackDict'].append({'name':track.name,\n",
    "                                              'artist':track.artists[0]['name'],\n",
    "                                              'trackObj':track,\n",
    "                                              'trackAA':aud,\n",
    "                                              'trackSegs':pd.DataFrame(aud['segments'])})\n",
    "                                     \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(genreDict,open('genreDict.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "c = ['b','g','r','c','m','y','k']\n",
    "f,ax = plt.subplots(4,1,figsize=(10,20))\n",
    "for key in list(genreDict.keys())[:2]:\n",
    "    s1=genreDict[key]['trackDict'][0]\n",
    "    segs = s1['trackSegs']\n",
    "    print('{}: {} - {}'.format(key,s1['name'],s1['artist']))\n",
    "    print(s1['trackObj'].features)\n",
    "    for i,data in enumerate(zip(segs.start,segs.pitches,segs.timbre,segs.loudness_max)):\n",
    "        start,pitches,timbre,mloudness = data\n",
    "        if i==0:\n",
    "            ax[0].scatter([start]*len(pitches),pitches,c=c[genreDict[key]['id']%len(c)],label=key)\n",
    "            ax[0].set_title('Pitches')\n",
    "            ax[1].scatter([start]*len(timbre),timbre,c=c[genreDict[key]['id']%len(c)],label=key)\n",
    "            ax[1].set_title('Timbres')\n",
    "            ax[2].plot(start,mloudness,c=c[genreDict[key]['id']%len(c)],label=key)\n",
    "            ax[2].set_title('Max Loudness')\n",
    "            handles,labels = ax[1].get_legend_handles_labels()\n",
    "        if i%25 == 0:\n",
    "            ax[0].scatter([start]*len(pitches),pitches,c=c[genreDict[key]['id']%len(c)])\n",
    "            ax[1].scatter([start]*len(timbre),timbre,c=c[genreDict[key]['id']%len(c)])\n",
    "            ax[2].plot(start,mloudness,c=c[genreDict[key]['id']%len(c)])\n",
    "\n",
    "ax[3].set_axis_off()\n",
    "ax[3].legend(handles,labels,ncol=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genreDict['Blues']['trackDict'][0]['trackSegs'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(genreDict.keys())[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa[0][0]['meta'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features, extract_relevant_features, select_features\n",
    "from tsfresh.examples.robot_execution_failures import download_robot_execution_failures, load_robot_execution_failures\n",
    "download_robot_execution_failures()\n",
    "df, y = load_robot_execution_failures()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = genreDict['Blues']['trackDict'][0]['trackSegs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=genreDict['Blues']['trackDict'][0]\n",
    "segs = s1['trackSegs']\n",
    "print('{}: {} - {}'.format(key,s1['name'],s1['artist']))\n",
    "print(s1['trackObj'].features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in s1['trackObj'].features.items():\n",
    "    segs[key] = val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "X = pd.DataFrame()\n",
    "y = []\n",
    "for i,genre in enumerate(genreDict.keys()):\n",
    "    for track in genreDict[genre]['trackDict']:\n",
    "        #print(track['trackObj'].features)\n",
    "        #print(track['trackSegs'].head())\n",
    "        segs = track['trackSegs']\n",
    "        segs['id'] = count\n",
    "        for key,val in track['trackObj'].features.items():\n",
    "            segs[key] = val\n",
    "        X = pd.concat([X,segs],ignore_index=True)\n",
    "        y.append(i)\n",
    "        count+=1\n",
    "    print('Finished {}'.format(genre))\n",
    "\n",
    "#Make the ID column the first column:\n",
    "cols = X.columns.tolist()\n",
    "idind = cols.index('id')\n",
    "cols = [cols[idind]]+cols[:idind]+cols[idind+1:]\n",
    "X = X[cols]\n",
    "\n",
    "#Create a pandas series for the y values\n",
    "y = pd.Series(y)\n",
    "\n",
    "#Save pickles\n",
    "print('Pickling...')\n",
    "X.to_pickle('X.p')\n",
    "y.to_pickle('y.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = pd.read_pickle('X.p')\n",
    "y = pd.read_pickle('y.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X['pitches'].values.tolist(),columns=['pitch_{}'.format(i) for i in range(len(X.pitches[0]))])\n",
    "df1 = pd.DataFrame(X['timbre'].values.tolist(),columns=['timbre_{}'.format(i) for i in range(len(X.timbre[0]))])\n",
    "X1 = X.drop(['pitches','timbre','loudness_end'],axis=1)\n",
    "X1 = pd.concat([X1,df,df1],axis=1)\n",
    "X1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[750:1400,['id','start']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tsfresh import extract_features, extract_relevant_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "extraction_settings = ComprehensiveFCParameters()\n",
    "X_ex = extract_features(X1.head(10000), column_id='id', impute_function=impute, \n",
    "                                       default_fc_parameters=extraction_settings)\n",
    "# Might have memory error. If so, do this outside of the jupyter notebook and save it to a csv or pickle\n",
    "\n",
    "X_ex = pd.read_pickle('X_ex.p')\n",
    "X_ex.shape\n",
    "\n",
    "from tsfresh.examples.har_dataset import download_har_dataset, load_har_dataset, load_har_classes\n",
    "download_har_dataset()\n",
    "df1 = load_har_dataset()\n",
    "df1.head()\n",
    "\n",
    "import numpy as np\n",
    "N = 500\n",
    "master_df = pd.DataFrame({0: df1[:N].values.flatten(),\n",
    "                          1: np.arange(N).repeat(df1.shape[1])})\n",
    "X = extract_features(master_df, column_id=1, impute_function=impute, default_fc_parameters=extraction_settings)\n",
    "y = load_har_classes()[:N]\n",
    "y.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "cl = DecisionTreeClassifier()\n",
    "cl.fit(X_train, y_train)\n",
    "print(classification_report(y_test, cl.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_features = set()\n",
    "\n",
    "for label in y.unique():\n",
    "    y_train_binary = y_train == label\n",
    "    X_train_filtered = select_features(X_train, y_train_binary)\n",
    "    print(\"Number of relevant features for class {}: {}/{}\".format(label, X_train_filtered.shape[1], X_train.shape[1]))\n",
    "    relevant_features = relevant_features.union(set(X_train_filtered.columns))\n",
    "\n",
    "X_train_filtered = X_train[list(relevant_features)]\n",
    "X_test_filtered = X_test[list(relevant_features)]\n",
    "cl = DecisionTreeClassifier()\n",
    "cl.fit(X_train_filtered, y_train)\n",
    "print(classification_report(y_test, cl.predict(X_test_filtered)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipython-sql\n",
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql sqlite://"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "CREATE TABLE writers (first_name,last_name,year_of_death);\n",
    "INSERT INTO writers VALUES ('Will','Shakespeare',1616);\n",
    "INSERT INTO writers VALUES ('Bertold', 'Brecht',1956);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql select * from writers where first_name = 'Will'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genreDict = pickle.load(open('genreDict.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.repeat(genreDict['Alternative Rock']['trackDict'][1]['trackSegs'].loudness_max.tolist(),12).reshape(-1,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = genreDict['Alternative Rock']['trackDict'][1]['trackSegs']\n",
    "p = np.array([i for i in b.pitches])\n",
    "t = np.array([i for i in b.timbre])\n",
    "l = np.repeat(b.loudness_max.tolist(),12).reshape(-1,12)\n",
    "c = np.repeat(b.confidence.tolist(),12).reshape(-1,12)\n",
    "print(p.shape,t.shape,l.shape,c.shape)\n",
    "combo = np.dstack((p,t,l,c))\n",
    "combo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genreDict['Alternative Rock']['trackDict'][1]['trackSegs'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genreTimeSeries = []\n",
    "genreMetaData = []\n",
    "y = []\n",
    "for i,genre in enumerate(genreDict.keys()):\n",
    "    y.append(np.ones((len(genreDict[genre]['trackList']),1))*i)\n",
    "    tseries = []\n",
    "    metaData = []\n",
    "    for track in genreDict[genre]['trackDict']:\n",
    "        s = track['trackSegs']\n",
    "        p = np.array([i for i in s.pitches])\n",
    "        t = np.array([i for i in s.timbre])\n",
    "        l = np.repeat(s.loudness_max.tolist(),12).reshape(-1,12)\n",
    "        d = np.repeat(s.duration.tolist(),12).reshape(-1,12)\n",
    "        c = np.repeat(s.confidence.tolist(),12).reshape(-1,12)\n",
    "        series_data = np.concatenate((p,t,l,d,c),axis=1)\n",
    "        tseries.append(series_data)\n",
    "        metaData.append(np.array([val for key,val in track['trackObj'].features.items()]).reshape(-1,1))\n",
    "        \n",
    "        \n",
    "    genreTimeSeries.append(tseries)\n",
    "    genreMetaData.append(metaData)\n",
    "    print('Finished {}'.format(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "maxlen = max([max([song.shape[0] for song in genre]) for genre in genreTimeSeries])\n",
    "padded = [pad_sequences(i,maxlen=maxlen) for i in genreTimeSeries]\n",
    "X = np.concatenate(padded)\n",
    "X_aux = np.concatenate(genreMetaData)\n",
    "print(X.shape,X_aux.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_cat = np.concatenate(y)\n",
    "y_cat = to_categorical(y_cat)\n",
    "num_classes = y_cat.shape[1]\n",
    "y_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test,y_train, y_test = train_test_split(X, y_cat, test_size=0.1,random_state=42)\n",
    "Xaux_train, Xaux_test,y_train1, y_test1 = train_test_split(X_aux, y_cat, test_size=0.1,random_state=42)\n",
    "print(X_train.shape,X_test.shape)\n",
    "print(Xaux_train.shape,Xaux_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array_equal(y_train,y_train1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# Headline input: meant to receive sequences of 100 integers, between 1 and 10000.\n",
    "# Note that we can name any layer by passing it a \"name\" argument.\n",
    "main_input = Input(shape=(X_train.shape[1:]), name='main_input')\n",
    "\n",
    "# A LSTM will transform the vector sequence into a single vector,\n",
    "# containing information about the entire sequence\n",
    "lstm_out = LSTM(32)(main_input)\n",
    "auxiliary_output = Dense(num_classes, activation='softmax', name='aux_output')(lstm_out)\n",
    "\n",
    "auxiliary_input = Input(shape=(12,), name='aux_input')\n",
    "\n",
    "x = keras.layers.concatenate([lstm_out, auxiliary_input])\n",
    "\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# And finally we add the main logistic regression layer\n",
    "main_output = Dense(num_classes, activation='softmax', name='main_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])\n",
    "\n",
    "# Replicates `model` on 4 GPUs.\n",
    "# This assumes that your machine has 4 available GPUs.\n",
    "parallel_model = multi_gpu_model(model, gpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
    "              loss_weights=[1., 0.2],metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = parallel_model.fit([X_train, Xaux_train.reshape(-1,12)], [y_train, y_train],validation_data=([X_test,Xaux_test.reshape(-1,12)],[y_test,y_test]),\n",
    "          epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizing features\n",
    "training on small segments of each song and averaging result (5 lstms for 5 song sections)\n",
    "balancing genre classes\n",
    "changing hyperparameters, learning rate scheduling\n",
    "removing aux loss\n",
    "training with only sequence data\n",
    "training with only metadata\n",
    "changing lstm to rnn or temporal conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('trainH')\n",
    "with open('trainHistoryDict', 'wb') as file_pi:\n",
    "        pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
